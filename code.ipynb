{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating BMI values from face-images using Keras and Transfer learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flow of the complete project\n",
    "1. Mounted g-drive for dataset and imported necessary libraries\n",
    "2. defined the dataset directory and other parameters, such as image width, height, batch size, and epochs.\n",
    "3. loaded the pre-trained VGG16 model,\n",
    "4. frozen the layers of the pre-trained model - so that pre-trained layers are not trained again and new layers can be added\n",
    "5. built the model by adding a flatten layer, a dense layer with 256 neurons, a dropout layer, and a dense layer with num_classes (5) neurons\n",
    "6. compiled the model by specifying the optimizer, loss function, and metrics\n",
    "7. loaded the data and labels from CSV files\n",
    "8. used ImageDataGenerator class (from Keras to perform data augmentation and ) to generate batches of images and their labels on the fly during training and validation.\n",
    "9. saved the model and its weights\n",
    "10. used ImageDataGenerator to generate batches of images for testing and predicted their BMI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset directory and other parameters\n",
    "data_dir = '/content/drive/MyDrive/finalBMI/check'\n",
    "img_width, img_height = 224, 224\n",
    "batch_size =32\n",
    "epochs = 20\n",
    "\n",
    "# Define the number of classes and train/val/test samples\n",
    "num_classes = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freezes the layers in the pre-trained VGG16 model so that they are not trainable. This is because we want to use the features extracted by the pre-trained model instead of retraining the entire model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the model & using tranfer learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,   # removes the final fully connected layers of the model, which will be replaced with new layers\n",
    "    input_shape=(img_width, img_height, 3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
